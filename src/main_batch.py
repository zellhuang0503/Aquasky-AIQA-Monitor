#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AQUASKY AIQA Monitor - å¤š LLM è‡ªå‹•åŒ–æ‰¹æ¬¡è™•ç†ä¸»ç¨‹å¼
æ”¯æ´ 8 ç¨® LLM è‡ªå‹•åŒ–è™•ç†ã€æ–·é»çºŒè·‘ã€æ™ºèƒ½æª”æ¡ˆå‘½åç­‰åŠŸèƒ½
"""

import os
import re
import sys
from pathlib import Path
from typing import List

# æ·»åŠ  src ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

from batch_processor import BatchProcessor


def load_questions(file_path: str) -> List[str]:
    """å¾ Markdown æª”æ¡ˆè¼‰å…¥å•é¡Œåˆ—è¡¨
    
    Args:
        file_path: å•é¡Œæª”æ¡ˆè·¯å¾‘
        
    Returns:
        å•é¡Œåˆ—è¡¨
    """
    if not os.path.exists(file_path):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°å•é¡Œæª”æ¡ˆ {file_path}")
        return []

    print(f"ğŸ“– è¼‰å…¥å•é¡Œæª”æ¡ˆ: {file_path}")
    questions = []
    
    # æ­£å‰‡è¡¨é”å¼åŒ¹é…ä»¥æ•¸å­—é–‹é ­çš„å•é¡Œè¡Œï¼Œä¾‹å¦‚ "1. ..."
    question_pattern = re.compile(r"^\d+\.\s.*")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if question_pattern.match(line):
                    # ç§»é™¤é–‹é ­çš„æ•¸å­—å’Œé»ï¼Œä¾‹å¦‚ "1. "
                    question_text = re.sub(r"^\d+\.\s", "", line)
                    questions.append(question_text)
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(questions)} å€‹å•é¡Œ")
        return questions
        
    except Exception as e:
        print(f"âŒ è®€å–å•é¡Œæª”æ¡ˆå¤±æ•—: {e}")
        return []


def get_user_model_selection(available_models: List[str]) -> List[str]:
    """è®“ç”¨æˆ¶é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹
    
    Args:
        available_models: å¯ç”¨æ¨¡å‹åˆ—è¡¨
        
    Returns:
        ç”¨æˆ¶é¸æ“‡çš„æ¨¡å‹åˆ—è¡¨
    """
    print(f"\nğŸ¤– å¯ç”¨çš„ LLM æ¨¡å‹:")
    for i, model in enumerate(available_models, 1):
        print(f"  {i}. {model}")
    
    print(f"\né¸æ“‡é¸é …:")
    print(f"  A. ä½¿ç”¨æ‰€æœ‰ {len(available_models)} å€‹æ¨¡å‹")
    print(f"  B. è‡ªè¨‚é¸æ“‡æ¨¡å‹")
    print(f"  C. ä½¿ç”¨é è¨­æ¨¡å‹ (å‰ 3 å€‹)")
    
    while True:
        choice = input("\nè«‹é¸æ“‡ (A/B/C): ").strip().upper()
        
        if choice == 'A':
            return available_models
        elif choice == 'C':
            return available_models[:3]
        elif choice == 'B':
            return get_custom_model_selection(available_models)
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥ Aã€B æˆ– C")


def get_custom_model_selection(available_models: List[str]) -> List[str]:
    """è®“ç”¨æˆ¶è‡ªè¨‚é¸æ“‡æ¨¡å‹
    
    Args:
        available_models: å¯ç”¨æ¨¡å‹åˆ—è¡¨
        
    Returns:
        ç”¨æˆ¶é¸æ“‡çš„æ¨¡å‹åˆ—è¡¨
    """
    print(f"\nè«‹è¼¸å…¥è¦ä½¿ç”¨çš„æ¨¡å‹ç·¨è™Ÿ (ç”¨é€—è™Ÿåˆ†éš”ï¼Œä¾‹å¦‚: 1,3,5):")
    
    while True:
        try:
            input_str = input("æ¨¡å‹ç·¨è™Ÿ: ").strip()
            if not input_str:
                print("âŒ è«‹è¼¸å…¥è‡³å°‘ä¸€å€‹æ¨¡å‹ç·¨è™Ÿ")
                continue
                
            # è§£æç”¨æˆ¶è¼¸å…¥
            indices = [int(x.strip()) for x in input_str.split(',')]
            
            # é©—è­‰ç·¨è™Ÿç¯„åœ
            if any(i < 1 or i > len(available_models) for i in indices):
                print(f"âŒ ç·¨è™Ÿå¿…é ˆåœ¨ 1-{len(available_models)} ç¯„åœå…§")
                continue
            
            # è½‰æ›ç‚ºæ¨¡å‹åç¨±
            selected_models = [available_models[i-1] for i in indices]
            
            print(f"âœ… å·²é¸æ“‡ {len(selected_models)} å€‹æ¨¡å‹:")
            for model in selected_models:
                print(f"  - {model}")
            
            return selected_models
            
        except ValueError:
            print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—ï¼Œç”¨é€—è™Ÿåˆ†éš”")


def show_progress_info(processor: BatchProcessor):
    """é¡¯ç¤ºé€²åº¦è³‡è¨Š"""
    progress = processor.progress
    
    if progress.get("completed"):
        completed_count = len(progress["completed"])
        total_tasks = progress.get("total_questions", 0) * len(progress.get("target_models", []))
        
        print(f"\nğŸ“Š é€²åº¦è³‡è¨Š:")
        print(f"  å·²å®Œæˆä»»å‹™: {completed_count}")
        print(f"  ç¸½ä»»å‹™æ•¸: {total_tasks}")
        if total_tasks > 0:
            print(f"  å®Œæˆç‡: {completed_count/total_tasks*100:.1f}%")
        
        if progress.get("failed"):
            print(f"  å¤±æ•—ä»»å‹™: {len(progress['failed'])}")


def main():
    """ä¸»ç¨‹å¼åŸ·è¡Œå‡½æ•¸"""
    print("ğŸš€ AQUASKY AIQA Monitor - å¤š LLM è‡ªå‹•åŒ–æ‰¹æ¬¡è™•ç†ç³»çµ±")
    print("=" * 60)
    
    # 1. è¨­å®šå°ˆæ¡ˆè·¯å¾‘
    project_root = Path(__file__).parent.parent
    print(f"ğŸ“ å°ˆæ¡ˆæ ¹ç›®éŒ„: {project_root}")
    
    # 2. è¼‰å…¥å•é¡Œ
            question_file = project_root / "AQUASKY AEO ç›£æ§å°ˆæ¡ˆ - é»ƒé‡‘å•é¡Œåº« V3.0.md"    questions = load_questions(str(question_file))
    
    if not questions:
        print("âŒ æ²’æœ‰è¼‰å…¥åˆ°å•é¡Œï¼Œç¨‹å¼çµæŸ")
        return

    # --- è‡¨æ™‚æ¸¬è©¦ä¿®æ”¹ï¼šåªä½¿ç”¨ç¬¬ä¸€å€‹å•é¡Œ ---
    questions = questions[:1]
    print("âš ï¸  æ³¨æ„ï¼šå·²å•Ÿç”¨è‡¨æ™‚æ¸¬è©¦æ¨¡å¼ï¼Œåƒ…ä½¿ç”¨ 1 å€‹å•é¡Œã€‚")
    # --- è‡¨æ™‚æ¸¬è©¦ä¿®æ”¹çµæŸ ---
    
    # 3. åˆå§‹åŒ–æ‰¹æ¬¡è™•ç†å™¨
    processor = BatchProcessor(str(project_root))
    
    # 4. é¡¯ç¤ºç¾æœ‰é€²åº¦
    show_progress_info(processor)
    
    # 5. é¸æ“‡æ¨¡å‹ (è‡¨æ™‚æ¸¬è©¦ä¿®æ”¹ï¼šè‡ªå‹•é¸æ“‡æ‰€æœ‰æ¨¡å‹)
    target_models = processor.available_models
    print("âš ï¸  æ³¨æ„ï¼šå·²å•Ÿç”¨è‡¨æ™‚æ¸¬è©¦æ¨¡å¼ï¼Œè‡ªå‹•é¸æ“‡æ‰€æœ‰å¯ç”¨æ¨¡å‹ã€‚")
    
    # 6. ç¢ºèªé–‹å§‹è™•ç†
    print(f"\nğŸ¯ è™•ç†æ‘˜è¦:")
    print(f"  å•é¡Œæ•¸é‡: {len(questions)}")
    print(f"  ç›®æ¨™æ¨¡å‹: {len(target_models)} å€‹")
    print(f"  ç¸½ä»»å‹™æ•¸: {len(questions) * len(target_models)}")
    print(f"  é ä¼°æ™‚é–“: {len(questions) * len(target_models) * 10 / 60:.1f} åˆ†é˜")
    
    print(f"\nğŸ“‹ ç›®æ¨™æ¨¡å‹åˆ—è¡¨:")
    for i, model in enumerate(target_models, 1):
        print(f"  {i}. {model}")
    
    # ç¢ºèªé–‹å§‹ (è‡¨æ™‚æ¸¬è©¦ä¿®æ”¹ï¼šè‡ªå‹•é–‹å§‹)
    print("âš ï¸  æ³¨æ„ï¼šå·²å•Ÿç”¨è‡¨æ™‚æ¸¬è©¦æ¨¡å¼ï¼Œè‡ªå‹•é–‹å§‹è™•ç†ã€‚")
    # while True:
    #     confirm = input(f"\næ˜¯å¦é–‹å§‹æ‰¹æ¬¡è™•ç†ï¼Ÿ(y/n): ").strip().lower()
    #     if confirm in ['y', 'yes', 'æ˜¯']:
    #         break
    #     elif confirm in ['n', 'no', 'å¦']:
    #         print("âŒ ç”¨æˆ¶å–æ¶ˆæ“ä½œ")
    #         return
    #     else:
    #         print("âŒ è«‹è¼¸å…¥ y æˆ– n")
    
    # 7. é–‹å§‹æ‰¹æ¬¡è™•ç†
    print(f"\nğŸ”„ é–‹å§‹æ‰¹æ¬¡è™•ç†...")
    print(f"ğŸ’¡ æç¤º: ç¨‹å¼æ”¯æ´æ–·é»çºŒè·‘ï¼Œå¯ä»¥éš¨æ™‚æŒ‰ Ctrl+C ä¸­æ–·")
    print(f"ğŸ’¾ è‡ªå‹•å­˜æª”: æ¯ {processor.config['auto_save_interval']} å€‹å•é¡Œè‡ªå‹•ä¿å­˜")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {processor.output_dir}")
    print(f"ğŸ“ æ—¥èªŒç›®éŒ„: {processor.log_dir}")
    
    try:
        results = processor.run_batch_processing(questions, target_models)
        
        # 8. é¡¯ç¤ºçµæœæ‘˜è¦
        print(f"\nğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
        print(f"ğŸ“Š çµæœæ‘˜è¦:")
        
        total_success = 0
        total_tasks = 0
        
        for model_name, model_results in results.items():
            success_count = len([r for r in model_results if not r["answer"].startswith("ERROR:")])
            total_success += success_count
            total_tasks += len(model_results)
            
            print(f"  {model_name}: {success_count}/{len(model_results)} æˆåŠŸ")
        
        print(f"  ç¸½æˆåŠŸç‡: {total_success}/{total_tasks} ({total_success/total_tasks*100:.1f}%)")
        
        # 9. æ¸…ç†é€²åº¦æª”æ¡ˆ (è‡¨æ™‚æ¸¬è©¦ä¿®æ”¹ï¼šè‡ªå‹•è·³é)
        print("âš ï¸  æ³¨æ„ï¼šå·²å•Ÿç”¨è‡¨æ™‚æ¸¬è©¦æ¨¡å¼ï¼Œè‡ªå‹•è·³éæ¸…ç†é€²åº¦æª”æ¡ˆçš„æ­¥é©Ÿã€‚")
        # cleanup = input(f"\næ˜¯å¦æ¸…ç†é€²åº¦æª”æ¡ˆï¼Ÿ(y/n): ").strip().lower()
        # if cleanup in ['y', 'yes', 'æ˜¯']:
        #     processor.cleanup_progress()
        #     print("âœ… é€²åº¦æª”æ¡ˆå·²æ¸…ç†")
        
        print(f"\nğŸ“ è«‹æª¢æŸ¥è¼¸å‡ºç›®éŒ„ä¸­çš„çµæœæª”æ¡ˆ: {processor.output_dir}")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ¶ä¸­æ–·ç¨‹å¼")
        print(f"ğŸ’¾ é€²åº¦å·²ä¿å­˜ï¼Œå¯ä»¥ç¨å¾Œç¹¼çºŒåŸ·è¡Œ")
        print(f"ğŸ“ éƒ¨åˆ†çµæœå·²ä¿å­˜è‡³: {processor.output_dir}")
        
    except Exception as e:
        print(f"\nâŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
        processor.logger.error(f"æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
