#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨™æº–åŒ–äº¤å‰åˆ†æåŸ·è¡Œå™¨
æ•´åˆæ‰€æœ‰åˆ†ææµç¨‹ï¼Œç¢ºä¿æ¯æ¬¡éƒ½é”åˆ°æ¨™æº–æ°´æº–
"""

import sys
import os
from pathlib import Path
from datetime import datetime

# æ·»åŠ  scripts ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent / "scripts"))

from scripts.generate_cross_analysis import CrossAnalysisGenerator
from scripts.quality_validator import ReportQualityValidator

class StandardizedAnalysisRunner:
    """æ¨™æº–åŒ–åˆ†æåŸ·è¡Œå™¨"""
    
    def __init__(self):
        self.generator = CrossAnalysisGenerator()
        self.validator = ReportQualityValidator()
        self.project_root = Path.cwd()
    
    def run_complete_analysis(self, date_pattern: str = None) -> dict:
        """åŸ·è¡Œå®Œæ•´çš„æ¨™æº–åŒ–åˆ†ææµç¨‹"""
        if not date_pattern:
            date_pattern = datetime.now().strftime("%Y%m%d")
        
        print(f"ğŸš€ é–‹å§‹åŸ·è¡Œæ¨™æº–åŒ–äº¤å‰åˆ†ææµç¨‹ - {date_pattern}")
        
        results = {
            'date_pattern': date_pattern,
            'report_generated': False,
            'report_path': None,
            'quality_validated': False,
            'quality_score': 0,
            'quality_report_path': None,
            'success': False,
            'errors': []
        }
        
        try:
            # æ­¥é©Ÿ 1: ç”Ÿæˆäº¤å‰åˆ†æå ±å‘Š
            print("\nğŸ“Š æ­¥é©Ÿ 1: ç”Ÿæˆäº¤å‰åˆ†æå ±å‘Š...")
            report_path = self.generator.generate_report(date_pattern)
            results['report_generated'] = True
            results['report_path'] = report_path
            print(f"âœ… å ±å‘Šç”Ÿæˆå®Œæˆ: {report_path}")
            
            # æ­¥é©Ÿ 2: é©—è­‰å ±å‘Šå“è³ª
            print("\nğŸ” æ­¥é©Ÿ 2: é©—è­‰å ±å‘Šå“è³ª...")
            validation_result = self.validator.validate_report(report_path)
            results['quality_validated'] = True
            results['quality_score'] = validation_result['quality_score']
            
            # ç”Ÿæˆå“è³ªæª¢æŸ¥å ±å‘Š
            quality_report = self.validator.generate_quality_report(validation_result)
            report_name = Path(report_path).stem
            quality_report_path = Path("outputs/cross_analysis") / f"{report_name}_quality_check.md"
            
            with open(quality_report_path, 'w', encoding='utf-8') as f:
                f.write(quality_report)
            
            results['quality_report_path'] = str(quality_report_path)
            print(f"ğŸ“Š å“è³ªåˆ†æ•¸: {validation_result['quality_score']:.1f}/100")
            print(f"ğŸ“ å“è³ªæª¢æŸ¥å ±å‘Š: {quality_report_path}")
            
            # æ­¥é©Ÿ 3: æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆ
            if validation_result['quality_score'] < 70:
                print("\nâš ï¸ æ­¥é©Ÿ 3: å“è³ªåˆ†æ•¸éä½ï¼Œå»ºè­°æª¢æŸ¥ä¸¦æ”¹å–„...")
                results['errors'].append(f"å“è³ªåˆ†æ•¸éä½: {validation_result['quality_score']:.1f}/100")
                
                for error in validation_result['errors']:
                    results['errors'].append(error)
                    print(f"   âŒ {error}")
                
                for warning in validation_result['warnings']:
                    print(f"   âš ï¸ {warning}")
            else:
                print(f"\nâœ… æ­¥é©Ÿ 3: å“è³ªé©—è­‰é€šé ({validation_result['quality_score']:.1f}/100)")
                results['success'] = True
            
            # æ­¥é©Ÿ 4: ç”ŸæˆåŸ·è¡Œæ‘˜è¦
            print("\nğŸ“‹ æ­¥é©Ÿ 4: ç”ŸæˆåŸ·è¡Œæ‘˜è¦...")
            summary = self._generate_execution_summary(results, validation_result)
            summary_path = Path("outputs/cross_analysis") / f"execution_summary_{date_pattern}.md"
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(summary)
            
            results['summary_path'] = str(summary_path)
            print(f"ğŸ“„ åŸ·è¡Œæ‘˜è¦: {summary_path}")
            
        except Exception as e:
            error_msg = f"åˆ†ææµç¨‹åŸ·è¡Œå¤±æ•—: {str(e)}"
            results['errors'].append(error_msg)
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
        
        return results
    
    def _generate_execution_summary(self, results: dict, validation_result: dict) -> str:
        """ç”ŸæˆåŸ·è¡Œæ‘˜è¦"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        summary = f"""# æ¨™æº–åŒ–äº¤å‰åˆ†æåŸ·è¡Œæ‘˜è¦

**åŸ·è¡Œæ™‚é–“**: {timestamp}
**åˆ†ææ—¥æœŸ**: {results['date_pattern']}
**åŸ·è¡Œç‹€æ…‹**: {'âœ… æˆåŠŸ' if results['success'] else 'âŒ å¤±æ•—'}

## åŸ·è¡Œçµæœ

### ğŸ“Š å ±å‘Šç”Ÿæˆ
- **ç‹€æ…‹**: {'âœ… å®Œæˆ' if results['report_generated'] else 'âŒ å¤±æ•—'}
- **å ±å‘Šè·¯å¾‘**: {results.get('report_path', 'N/A')}

### ğŸ” å“è³ªé©—è­‰
- **ç‹€æ…‹**: {'âœ… å®Œæˆ' if results['quality_validated'] else 'âŒ å¤±æ•—'}
- **å“è³ªåˆ†æ•¸**: {results['quality_score']:.1f}/100
- **å“è³ªç­‰ç´š**: {self._get_quality_grade(results['quality_score'])}
- **é©—è­‰å ±å‘Š**: {results.get('quality_report_path', 'N/A')}

## å“è³ªæª¢æŸ¥è©³æƒ…

"""
        
        if 'checks' in validation_result:
            for check_name, check_result in validation_result['checks'].items():
                status = 'âœ…' if check_result['passed'] else 'âŒ'
                summary += f"- **{check_name.replace('_', ' ').title()}**: {status}\n"
        
        if results['errors']:
            summary += "\n## âŒ ç™¼ç¾å•é¡Œ\n"
            for error in results['errors']:
                summary += f"- {error}\n"
        
        summary += f"""
## ğŸ“ˆ æ”¹å–„å»ºè­°

### ç«‹å³æ”¹å–„
- ç¢ºä¿æ‰€æœ‰å¿…éœ€ç« ç¯€å®Œæ•´
- è£œå……é‡åŒ–æ•¸æ“šå’ŒæŒ‡æ¨™
- å®Œå–„æ¨¡å‹æ’ååˆ†æ

### æŒçºŒå„ªåŒ–
- å®šæœŸæª¢æŸ¥å ±å‘Šå“è³ª
- æ›´æ–°åˆ†ææ¨™æº–
- æ”¹å–„è‡ªå‹•åŒ–æµç¨‹

## ğŸ”„ ä¸‹æ¬¡åŸ·è¡Œ

å»ºè­°ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“: {datetime.now().strftime("%Y-%m-%d")} (ä¸€é€±å¾Œ)

---
**ç”Ÿæˆå·¥å…·**: æ¨™æº–åŒ–äº¤å‰åˆ†æåŸ·è¡Œå™¨ v1.0
"""
        
        return summary
    
    def _get_quality_grade(self, score: float) -> str:
        """ç²å–å“è³ªç­‰ç´š"""
        if score >= 90:
            return "ğŸ† å„ªç§€"
        elif score >= 80:
            return "ğŸ¥ˆ è‰¯å¥½"
        elif score >= 70:
            return "ğŸ¥‰ åŠæ ¼"
        elif score >= 60:
            return "âš ï¸ å¾…æ”¹å–„"
        else:
            return "âŒ ä¸åŠæ ¼"

def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¨™æº–åŒ–äº¤å‰åˆ†æåŸ·è¡Œå™¨')
    parser.add_argument('--date', '-d', help='åˆ†ææ—¥æœŸ (æ ¼å¼: YYYYMMDD)', default=None)
    parser.add_argument('--force', '-f', action='store_true', help='å¼·åˆ¶é‡æ–°ç”Ÿæˆå ±å‘Š')
    
    args = parser.parse_args()
    
    runner = StandardizedAnalysisRunner()
    results = runner.run_complete_analysis(args.date)
    
    print(f"\n{'='*60}")
    print(f"æ¨™æº–åŒ–åˆ†æåŸ·è¡Œå®Œæˆ")
    print(f"{'='*60}")
    print(f"åŸ·è¡Œç‹€æ…‹: {'âœ… æˆåŠŸ' if results['success'] else 'âŒ å¤±æ•—'}")
    print(f"å“è³ªåˆ†æ•¸: {results['quality_score']:.1f}/100")
    
    if results['success']:
        print(f"ğŸ“Š åˆ†æå ±å‘Š: {results['report_path']}")
        print(f"ğŸ” å“è³ªå ±å‘Š: {results['quality_report_path']}")
        print(f"ğŸ“‹ åŸ·è¡Œæ‘˜è¦: {results['summary_path']}")
    else:
        print("âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç¾å•é¡Œ:")
        for error in results['errors']:
            print(f"   - {error}")
    
    return 0 if results['success'] else 1

if __name__ == "__main__":
    exit(main())
